{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *\n",
    "from utils import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "#matrices and vectorization\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#models \n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "# from sklearn import column_transformer \n",
    "from sklearn.pipeline import Pipeline\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "seed = pre_process_config['seed']\n",
    "np.random.seed(seed)\n",
    "kfold = StratifiedKFold(n_splits=10, random_state=seed, shuffle=True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data \n",
    "df = pd.read_csv(list_dir['data_dir'],encoding='utf-8')\n",
    "input_data=df['Title_description']\n",
    "targets =df[label_['label_list']]\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preporcessing steps \n",
    " 1. Remove all the shaffling of the data \n",
    " 2. remove the number \n",
    " 3. remove the punctuation\n",
    " 4. remove the stop words\n",
    " 5. remove the prenthesis \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_data,targets = shuffle_data(input_data,targets) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'বোনাস দিতে পারবে আমরা টেকনোলজিস: পুঁজিবাজারে আইটি খাতে তালিকাভুক্ত কোম্পানি আমরা টেকনোলজিসের ঘোষিত বোনাস লভ্যাংশ প্রদানে সম্মতি দিয়েছে নিয়ন্ত্রক সংস্থা বাংলাদেশ সিকিউরিটিজ অ্যান্ড এক্সচেঞ্জ কমিশন (বিএসইসি)।ঢাকা স্টক এক্সচেঞ্জ (ডিএসই) সূত্রে এ তথ্য জানা গেছে।তথ্য মতে, আমরা টেকনোলজিসের ২০২২ সালের ৩০ জুনে সমাপ্ত হিসাব বছরের আর্থিক প্রতিবেদন পর্যালোচনা করে শেয়ারহোল্ডারদের জন্য ৬ শতাংশ বোনাস লভ্যাংশ ঘোষণা করে।আইন অনুযায়ী বিএসইসির অনুমোদন ছাড়া কোনো কোম্পানি বোনাস শেয়ার ইস্যু করতে পারবে না। তাই বোনাস শেয়ার ঘোষণার পর এই কোম্পানিটি তা বিতরণে নিয়ন্ত্রক সংস্থার সম্মতির জন্য আবেদন করে। নিয়ন্ত্রক সংস্থা কোম্পানিটিকে বোনাস লভ্যাংশ বিতরণে সম্মতি দিয়েছে।'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data[55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_stopwords = pre_process_config['stop_word']\n",
    "main_stopwords =list_stopwords.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove stopwords\n",
    "def remove_stopwords(text):\n",
    "    text = ' '.join([word for word in text.split() if word not in main_stopwords])\n",
    "    return text\n",
    "\n",
    "input_data = input_data.apply(lemmatize_text)\n",
    "input_data= input_data.apply(remove_prone)\n",
    "input_data = input_data.apply(remove_numbers)\n",
    "input_data = input_data.apply(remove_english_words)\n",
    "input_data = input_data.apply(remove_stopwords)\n",
    "input_data = input_data.apply(remove_perenthesis)\n",
    "input_data = input_data.apply(remove_dash)\n",
    "input_data = input_data.apply(remove_extra_spaces)\n",
    "input_data = input_data.apply(remove_3rdbreket)\n",
    "input_data = input_data.apply(remove_symbols) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(input_data, targets, test_size=0.2, random_state=0)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "X_val = vectorizer.transform(X_val)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model slecetion with cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf = OneVsRestClassifier(LinearSVC(random_state=0))\n",
    "#make 10 fold cross validation \n",
    "display_scores(cross_val_score(clf, X_train, y_train, cv=10, scoring=\"accuracy\"))\n",
    "\n",
    "'''\n",
    "    Scores: [0.79620853 0.81042654 0.79810427 0.79336493 0.81119545 0.79791271\n",
    "    0.79886148 0.79316888 0.80929791 0.82827324]\n",
    "    Mean: 0.80368139428222\n",
    "    Standard deviation: 0.010481708200214835 \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.87677725 0.86255924 0.87582938 0.86635071 0.88614801 0.89184061\n",
      " 0.85673624 0.89278937 0.86907021 0.88709677]\n",
      "Mean: 0.8765197802098978\n",
      "Standard deviation: 0.01204050243526496\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n    Scores: [0.80473934 0.81516588 0.80379147 0.80663507 0.82637571 0.80929791\\n    0.80550285 0.80265655 0.81499051 0.84345351]\\n    Mean: 0.8132608793402699\\n    Standard deviation: 0.012185016433768013\\n    \\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#svm classifier    \n",
    "clf = OneVsRestClassifier(svm.SVC(kernel='linear', C=5, gamma=1))\n",
    "#make 10 fold cross validation\n",
    "clf=display_scores(cross_val_score(clf, X_train, y_train, cv=10, scoring=\"accuracy\"))\n",
    "\n",
    "'''\n",
    "    Scores: [0.80473934 0.81516588 0.80379147 0.80663507 0.82637571 0.80929791\n",
    "    0.80550285 0.80265655 0.81499051 0.84345351]\n",
    "    Mean: 0.8132608793402699\n",
    "    Standard deviation: 0.012185016433768013\n",
    "    \n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.88815166 0.90521327 0.8957346  0.90616114 0.90702087 0.89278937\n",
      " 0.88709677 0.89658444 0.88804554 0.88994307]\n",
      "Mean: 0.8956740739408439\n",
      "Standard deviation: 0.007483810624972298\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n    Scores: [0.83033175 0.81706161 0.82748815 0.8        0.82352941 0.83206831\\n    0.80645161 0.80075901 0.80929791 0.84535104]\\n    Mean: 0.8192338822090524\\n    Standard deviation: 0.014264177653053867\\n\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dt classifier \n",
    "clf = OneVsRestClassifier(DecisionTreeClassifier(random_state=0))\n",
    "#10 fold cross validation\n",
    "clf=display_scores(cross_val_score(clf, X_train, y_train, cv=10, scoring=\"accuracy\"))\n",
    "#display_scores(cross_val_score(clf, X_train, y_train, cv=10, scoring=\"accuracy\"))\n",
    "'''\n",
    "    Scores: [0.83033175 0.81706161 0.82748815 0.8        0.82352941 0.83206831\n",
    "    0.80645161 0.80075901 0.80929791 0.84535104]\n",
    "    Mean: 0.8192338822090524\n",
    "    Standard deviation: 0.014264177653053867\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.78862559 0.7971564  0.78862559 0.78957346 0.80645161 0.82163188\n",
      " 0.77324478 0.81214421 0.80550285 0.81878558]\n",
      "Mean: 0.8001741953469969\n",
      "Standard deviation: 0.014599020633185453\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n    Scores: [0.75165877 0.75924171 0.75734597 0.73080569 0.74383302 0.73529412\\n    0.73339658 0.73529412 0.72106262 0.76375712]\\n    Mean: 0.7431689703858917\\n    Standard deviation: 0.01347878794175505\\n\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#logistic regression classifier \n",
    "clf = OneVsRestClassifier(LogisticRegression(random_state=0))\n",
    "#make 10 fold cross validation\n",
    "display_scores(cross_val_score(clf, X_train, y_train, cv=10, scoring=\"accuracy\"))\n",
    "\n",
    "'''\n",
    "    Scores: [0.75165877 0.75924171 0.75734597 0.73080569 0.74383302 0.73529412\n",
    "    0.73339658 0.73529412 0.72106262 0.76375712]\n",
    "    Mean: 0.7431689703858917\n",
    "    Standard deviation: 0.01347878794175505\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#naive bayes classifier \n",
    "clf = OneVsRestClassifier(MultinomialNB())\n",
    "#10 fold cross validation\n",
    "display_scores(cross_val_score(clf, X_train, y_train, cv=10, scoring=\"accuracy\"))\n",
    "\n",
    "'''\n",
    "    Scores: [0.50521327 0.5478673  0.53175355 0.50047393 0.54079696 0.5370019\n",
    "    0.51612903 0.51328273 0.49240987 0.53605313]\n",
    "    Mean: 0.5220981681160463\n",
    "    Standard deviation: 0.018086532757600096\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#knn classifier \n",
    "clf = OneVsRestClassifier(KNeighborsClassifier(n_neighbors=3))\n",
    "display_scores(cross_val_score(clf, X_train, y_train, cv=10, scoring=\"accuracy\"))\n",
    "\n",
    "'''\n",
    "    Scores: [0.72890995 0.75165877 0.72511848 0.71279621 0.74762808 0.72296015\n",
    "    0.72390892 0.71157495 0.71157495 0.75142315]\n",
    "    Mean: 0.7287553621050928\n",
    "    Standard deviation: 0.01519843741387436\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradient boosting classifier \n",
    "clf = OneVsRestClassifier(GradientBoostingClassifier(random_state=0))\n",
    "display_scores(cross_val_score(clf, X_train, y_train, cv=10, scoring=\"accuracy\"))\n",
    "\n",
    "\n",
    "'''\n",
    "    Scores: [0.83696682 0.83127962 0.82559242 0.82369668 0.82827324 0.83965844\n",
    "    0.81024668 0.81119545 0.81688805 0.85009488]\n",
    "    Mean: 0.8273892281266579\n",
    "    Standard deviation: 0.01207050517222523\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make adaboost classifier \n",
    "clf = OneVsRestClassifier(AdaBoostClassifier(random_state=0))\n",
    "display_scores(cross_val_score(clf, X_train, y_train, cv=10, scoring=\"accuracy\"))\n",
    "'''\n",
    "    Scores: [0.80947867 0.7943128  0.78672986 0.77156398 0.80455408 0.79222011\n",
    "    0.79411765 0.78842505 0.79601518 0.80740038]\n",
    "    Mean: 0.7944817755874709\n",
    "    Standard deviation: 0.01059659213112092\n",
    "\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### summary \n",
    "\n",
    "##### Model evaluated \n",
    "Logistic Regression ,2. XGBoost , 3. SVM ,4. Naive Bayes ,5. KNN ,6. Decision Tree,7. AdaBoost ,8. Gradient Boosting ,9. Voting Classifier \n",
    "Model Evaluation base on Accuracy \n",
    "best performing model (accuracy >= 0.8)--> gradient boosting ,2. svm ,3. dt ,4. adaboost \n",
    " \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hyper parameter tuning \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# desion tree classifier parameters \n",
    "from sklearn.model_selection import GridSearchCV   \n",
    "clf = DecisionTreeClassifier(random_state=0) \n",
    "param_grid = [{ \n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'splitter': ['best', 'random'],\n",
    "    'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20],\n",
    "    \n",
    "}]\n",
    "#make grid search\n",
    "CV_clf = GridSearchCV(estimator=clf, param_grid=param_grid, cv= 10)\n",
    "CV_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#best parameters \n",
    "#print(CV_clf.best_params_) -->DecisionTreeClassifier(criterion='entropy', max_depth=20, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=DecisionTreeClassifier(criterion='entropy',\n",
       "                                                     max_depth=20,\n",
       "                                                     random_state=0))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_clf_best = OneVsRestClassifier(DecisionTreeClassifier(criterion='entropy', max_depth=20, random_state=0))\n",
    "dt_clf_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\Amzad\\\\Desktop\\\\news_classifcation\\\\project\\\\logs\\\\model_ckpts\\\\dt_clf_best.pkl']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#store the best model ckpt \n",
    "import joblib\n",
    "joblib.dump(dt_clf_best, r'C:\\Users\\Amzad\\Desktop\\news_classifcation\\project\\logs\\model_ckpts\\dt_clf_best.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make predictions\n",
    "y_pred = dt_clf_best.predict(X_test)\n",
    "y_pred = pd.DataFrame(y_pred, columns=targets.columns)\n",
    "y_pred.head()\n",
    "\n",
    "#save predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use default parameters, and train and test with small set of samples.\n",
    "svm_clf = OneVsRestClassifier(SVC())\n",
    "param_grid = {'estimator__C': [0.1, 1, 10, 100, 1000],  \n",
    "              'estimator__gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "              'estimator__kernel': ['rbf'],\n",
    "              'estimator__class_weight': ['balanced', None]}  \n",
    "\n",
    "\n",
    "\n",
    "#make grid search\n",
    "svm_clf_best = GridSearchCV(svm_clf, param_grid, cv=5, n_jobs=-1)\n",
    "svm_clf_best.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "'''\n",
    "{'estimator__C': 10, 'estimator__gamma': 1, 'estimator__kernel': 'rbf'}\n",
    "0.8566952151392379\n",
    "OneVsRestClassifier(estimator=SVC(C=10, gamma=1))\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=SVC(C=10, gamma=1))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train with best parameters \n",
    "svm_clf_best = OneVsRestClassifier(estimator=SVC(C=10, gamma=1))\n",
    "svm_clf_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\Amzad\\\\Desktop\\\\news_classifcation\\\\project\\\\logs\\\\model_ckpts\\\\svm_clf_best.pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(svm_clf_best, r'C:\\Users\\Amzad\\Desktop\\news_classifcation\\project\\logs\\model_ckpts\\svm_clf_best.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV \n",
    "ada_clf = OneVsRestClassifier(AdaBoostClassifier(random_state=0))\n",
    "param_grid = [{'estimator__n_estimators': [50, 100, 200, 300 ],\n",
    "                'estimator__learning_rate': [0.1, 0.2, 0.3,],\n",
    "                'estimator__algorithm': ['SAMME', 'SAMME.R'],\n",
    "                'estimator__random_state': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "            }]\n",
    "\n",
    "#make grid search\n",
    "\n",
    "gs_clf = GridSearchCV(ada_clf, param_grid, cv=4, n_jobs=-1)\n",
    "gs_clf.fit(X_train, y_train)\n",
    "''' best parameters\n",
    "OneVsRestClassifier(estimator=AdaBoostClassifier(learning_rate=0.3,\n",
    "                                                 n_estimators=300,\n",
    "                                                 random_state=0))\n",
    "\n",
    "'''\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=AdaBoostClassifier(learning_rate=0.3,\n",
       "                                                 n_estimators=300,\n",
       "                                                 random_state=0))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train with best parameters \n",
    "gs_clf = OneVsRestClassifier(AdaBoostClassifier(learning_rate=0.3,\n",
    "                                                 n_estimators=300,\n",
    "                                                 random_state=0))\n",
    "gs_clf.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\Amzad\\\\Desktop\\\\news_classifcation\\\\project\\\\logs\\\\model_ckpts\\\\gs_clf_best.pkl']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(gs_clf, r'C:\\Users\\Amzad\\Desktop\\news_classifcation\\project\\logs\\model_ckpts\\gs_clf_best.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make gradient boosting classifier with best parameters\n",
    "'''\n",
    "this model takes a long time to train, so tune it once with small set of parameters, and then never tune it again\n",
    "\n",
    "'''\n",
    "gb_clf = OneVsRestClassifier(GradientBoostingClassifier(random_state=0))\n",
    "param_grid = [{\n",
    "    'estimator__n_estimators': [300, 400, 500],\n",
    "    'estimator__max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "}]\n",
    "\n",
    "#make grid search\n",
    "gs_clf = GridSearchCV(gb_clf, param_grid, cv=5, n_jobs=-1)\n",
    "gs_clf.fit(X_train, y_train)\n",
    "\n",
    "#never tune it again \n",
    "#best parameters are {'estimator__max_depth': 10, 'estimator__min_samples_leaf': 1, 'estimator__min_samples_split': 2, 'estimator__n_estimators': 500}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=GradientBoostingClassifier(max_depth=10,\n",
       "                                                         n_estimators=500,\n",
       "                                                         random_state=0))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train with best parameters \n",
    "gb_clf_best= OneVsRestClassifier(GradientBoostingClassifier(random_state=0, max_depth=10, n_estimators=500, min_samples_leaf=1, min_samples_split=2))\n",
    "gb_clf_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\Amzad\\\\Desktop\\\\news_classifcation\\\\project\\\\logs\\\\model_ckpts\\\\gb_clf_best.pkl']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(gb_clf_best, r'C:\\Users\\Amzad\\Desktop\\news_classifcation\\project\\logs\\model_ckpts\\gb_clf_best.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make voting classifier with best parameters \n",
    "from sklearn.ensemble import VotingClassifier\n",
    "voting_clf = OneVsRestClassifier(VotingClassifier( estimators=[('svm', svm_clf_best), ('dt', dt_clf_best), ('gb', gb_clf_best), ('ada', gs_clf)], voting='soft'))\n",
    "voting_clf.fit(X_train, y_train)\n",
    "#make predictions on validation set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump the model to ml_model_ckpt_dir \n",
    "import pickle\n",
    "pickle.dump(voting_clf, open('C:\\Users\\Amzad\\Desktop\\news_classifcation\\project\\logs\\model_ckpts\\voting_clf.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import voting_with_model \n",
    "\n",
    "\n",
    "#make predictions on validation set\n",
    "y_pred = voting_with_model([svm_clf_best, dt_clf_best, gb_clf_best, gs_clf], X_val[45])\n",
    "y_pred = pd.DataFrame(y_pred, columns=targets.columns)\n",
    "\n",
    "\n",
    "#compare with actual labels\n",
    "print(y_val.iloc[45])\n",
    "print(y_pred)\n",
    "\n",
    "\n",
    "\n",
    "#make predictions on validation set\n",
    "y_pred = voting_with_model([svm_clf_best, dt_clf_best, gb_clf_best, gs_clf], X_val)\n",
    "y_pred = pd.DataFrame(y_pred, columns=targets.columns)\n",
    "\n",
    "#evaluate the model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test on test set    \n",
    "y_pred = voting_with_model([svm_clf_best, dt_clf_best, gb_clf_best, gs_clf], X_test)\n",
    "y_pred = pd.DataFrame(y_pred, columns=targets.columns)\n",
    "y_pred.head()\n",
    "\n",
    "#print the accuracy function \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4ef60fdc05b8c9d7c00029e41ed6e96799336c5489ef8cc1e2e0d70e844fa01c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
