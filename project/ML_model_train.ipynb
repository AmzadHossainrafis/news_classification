{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "#matrices and vectorization\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#models \n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = r'C:\\Users\\Amzad\\Desktop\\news_analysis\\data\\pre-processed-data\\data_with_15%_no_label.csv'\n",
    "seed = 40 \n",
    "np.random.seed(seed)\n",
    "kfold = StratifiedKFold(n_splits=10, random_state=seed, shuffle=True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data \n",
    "df = pd.read_csv(data_dir,encoding='utf-8')\n",
    "input_data=df['Title_description']\n",
    "\n",
    "#if new keywords are added, add them here , but need to preprocess them first\n",
    "targets =df[['ক্রেডিট রেটিং','পর্ষদ সভা','ইপিএস',\"প্রান্তিক প্রকাশ\",'পিই রেশিও','ডিভিডেন্ড','ব্লক মার্কেট','স্পট মার্কেট','লভ্যাংশ ঘোষণা']]\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preporcessing steps \n",
    " 1. Remove all the shaffling of the data \n",
    " 2. remove the number \n",
    " 3. remove the punctuation\n",
    " 4. remove the stop words\n",
    " 5. remove the prenthesis \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing random shuffle \n",
    "def shuffle_data(input_data,targets): \n",
    "    shuffle=np.random.permutation(len(input_data))\n",
    "    input_data=input_data[shuffle]\n",
    "    targets=targets.iloc[shuffle]   \n",
    "    return input_data,targets\n",
    "\n",
    "#preprocessing\n",
    "input_data,targets = shuffle_data(input_data,targets) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data[55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "724\n"
     ]
    }
   ],
   "source": [
    "list1='অবশ্য অনেক অনেকে অনেকেই অন্তত অথবা অথচ অর্থাত অন্য আজ আছে আপনার আপনি আবার আমরা আমাকে আমাদের আমার আমি আরও আর আগে আগেই আই অতএব আগামী অবধি অনুযায়ী আদ্যভাগে এই একই একে একটি এখন এখনও এখানে এখানেই এটি এটা এটাই এতটাই এবং একবার এবার এদের এঁদের এমন এমনকী এল এর এরা এঁরা এস এত এতে এসে একে এ ঐ ই ইহা ইত্যাদি উনি উপর উপরে উচিত ও ওই ওর ওরা ওঁর ওঁরা ওকে ওদের ওঁদের ওখানে কত কবে করতে কয়েক কয়েকটি করবে করলেন করার কারও করা করি করিয়ে করার করাই করলে করলেন করিতে করিয়া করেছিলেন করছে করছেন করেছেন করেছে করেন করবেন করায় করে করেই কাছ কাছে কাজে কারণ কিছু কিছুই কিন্তু কিংবা কি কী কেউ কেউই কাউকে কেন কে কোনও কোনো কোন কখনও ক্ষেত্রে খুব\tগুলি গিয়ে গিয়েছে গেছে গেল গেলে গোটা চলে ছাড়া ছাড়াও ছিলেন ছিল জন্য জানা ঠিক তিনি তিনঐ তিনিও তখন তবে তবু তাঁদের তাঁাহারা তাঁরা তাঁর তাঁকে তাই তেমন তাকে তাহা তাহাতে তাহার তাদের তারপর তারা তারৈ তার তাহলে তিনি তা তাও তাতে তো তত তুমি তোমার তথা থাকে থাকা থাকায় থেকে থেকেও থাকবে থাকেন থাকবেন থেকেই দিকে দিতে দিয়ে দিয়েছে দিয়েছেন দিলেন দু দুটি দুটো দেয় দেওয়া দেওয়ার দেখা দেখে দেখতে দ্বারা ধরে ধরা নয় নানা না নাকি নাগাদ নিতে নিজে নিজেই নিজের নিজেদের নিয়ে নেওয়া নেওয়ার নেই নাই পক্ষে পর্যন্ত পাওয়া পারেন পারি পারে পরে পরেই পরেও পর পেয়ে প্রতি প্রভৃতি প্রায় ফের ফলে ফিরে ব্যবহার বলতে বললেন বলেছেন বলল বলা বলেন বলে বহু বসে বার বা বিনা বরং বদলে বাদে বার বিশেষ বিভিন্ন\tবিষয়টি ব্যবহার ব্যাপারে ভাবে ভাবেই মধ্যে মধ্যেই মধ্যেও মধ্যভাগে মাধ্যমে মাত্র মতো মতোই মোটেই যখন যদি যদিও যাবে যায় যাকে যাওয়া যাওয়ার যত যতটা যা যার যারা যাঁর যাঁরা যাদের যান যাচ্ছে যেতে যাতে যেন যেমন যেখানে যিনি যে রেখে রাখা রয়েছে রকম শুধু সঙ্গে সঙ্গেও সমস্ত সব সবার সহ সুতরাং সহিত সেই সেটা সেটি সেটাই সেটাও সম্প্রতি সেখান সেখানে সে স্পষ্ট স্বয়ং হইতে হইবে হৈলে হইয়া হচ্ছে হত হতে হতেই হবে হবেন হয়েছিল হয়েছে হয়েছেন হয়ে হয়নি হয় হয়েই হয়তো হল হলে হলেই হলেও হলো হিসাবে হওয়া হওয়ার হওয়ায় হন হোক জন জনকে জনের জানতে জানায় জানিয়ে জানানো জানিয়েছে জন্য জন্যওজে জে বেশ দেন তুলে ছিলেন চান চায় চেয়ে মোট যথেষ্ট টি ১ ২ ৩ ৪ ৫ ৬ ৭ ৮ ৯'\n",
    "list_stopwords = list1+\"একটি নিজের তারৈ আমি ঐ আপনি করিয়ে তত জন্য যখন হত সেটাও করার ওঁদের শুধু তাহার ওদের দেওয়ার নিজেই আমার দিলেন ফিরে গেলে জানা আপনার তাঁর উপর তাকে রয়েছে যাকে এঁরা তাদের সেই হবেন কোনও অনুযায়ী যান তাও পরেও গেছে অবধি কয়েকটি কাছে এটি আগেই এতটাই হইয়া যা হৈলে আবার তারা সে হয়েছে সহিত যাবে তখন গিয়েছে দিয়ে কিছুই তবে নিতে রেখে ই সহ যাঁরা নানা হলো যাঁর তোমার পর ছাড়াও করলে যত তবু তিনিও না দেখতে দেওয়া থেকেও কাজে ক্ষেত্রে কয়েক হচ্ছে হয়েছিল থেকেই অথবা সঙ্গেও বদলে দ্বারা পক্ষে গেল বলতে পাওয়া কত মধ্যে বলা জে নেই তাই কি সেটা একে যেখানে এত হলেও টি করেই করছে হন প্রায় মধ্যভাগে কারণ এবার করেছে করেন আর যেন নিজেদের হয়েই নিজে একবার নাই বাদে যাতে এর ঠিক তার ও পেয়ে করলেন মোট ব্যাপারে কাছ করা চেয়ে কেউ নাগাদ করি বলেছেন নেওয়ার কাউকে ভাবে দিকে তারপর যেমন ওখানে খুব\tগুলি অর্থাত তো ছিলেন কোন পারেন হয়তো বরং কেউই জনকে প্রভৃতি দুটো তাঁকে এখন অন্য ওর ছিল ওকে তুলে দিয়েছে জানানো ওঁরা এটাই তুমি করিতে তাহলে দেন বলে যে হলেই এমনকী হল বহু বলল মধ্যেই ধরে তাঁদের তেমন আই হইবে তাহাতে নেওয়া যিনি এঁদের অনেকে হতে কে ধরা হইতে করায় ব্যবহার থাকে বসে থাকেন থাকবে স্বয়ং এরা দেয় নিয়ে কবে সবার দেখে চলে যেতে ইত্যাদি সেখান চান অন্তত হবে সেটাই পর্যন্ত মাধ্যমে এমন ভাবেই দিয়েছেন ওরা করে তাতে এবং এতে ইহা জন্যওজে সুতরাং আমাকে বিশেষ এসে করতে এখানেই আমরা কিন্তু তিনি বিনা আজ কারও করিয়া তা ছাড়া থেকে যারা হয় হওয়া এল মাত্র ফের জানতে জানিয়ে বললেন মতোই সাথে কর করেছেন করবেন হলে নাকি সঙ্গে আগামী এখনও তাঁাহারা দিতে তাঁরা আগে আমাদের সেটি বলেন স্পষ্ট কোনো হোক থাকবেন জন করছেন অবশ্য গিয়ে হয়নি এখানে করবে কিছু হওয়ায় কখনও যাদের বার হয়ে পারি জানিয়েছে আদ্যভাগে আরও মতো যায় যাওয়ার কিংবা যদি পরেই জনের হিসাবে এস দুটি জানায় গোটা যাওয়া তথা সমস্ত যদিও করাই হতেই হয়েছেন নয় বিভিন্ন\tবিষয়টি রকম অনেক করেছিলেন উপরে এ এদের উনি হয় সব পরে প্রতি যার মধ্যেও মোটেই এই বা বেশ পারে যতটা অনেকেই যাচ্ছে অথচ অতএব একই দেখা চায় আছে থাকায় যথেষ্ট কী তাহা রাখা ওঁর সেখানে সম্প্রতি তিনঐ উচিত হওয়ার ফলে ওই কেন থাকা এটা\"\n",
    "main_stopwords =list_stopwords.split(\" \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove numbers\n",
    "def remove_numbers(text):\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    return text\n",
    "\n",
    "#remove extra spaces\n",
    "def remove_extra_spaces(text):\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text\n",
    "\n",
    "#remove english words\n",
    "def remove_english_words(text):\n",
    "    text = re.sub(r'[a-zA-Z]', '', text)\n",
    "    return text\n",
    "\n",
    "#remove stopwords\n",
    "def remove_stopwords(text):\n",
    "    text = ' '.join([word for word in text.split() if word not in main_stopwords])\n",
    "    return text\n",
    "\n",
    "#remove all perenthesis \n",
    "def remove_perenthesis(text):\n",
    "    text = re.sub(r'\\([^)]*\\)', '', text)\n",
    "    return text\n",
    "\n",
    "#remove all -pron-\n",
    "def remove_prone(text):\n",
    "    text = re.sub(r'-pron-', '', text)\n",
    "    return text\n",
    "\n",
    "#remove symbols\n",
    "def remove_symbols(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "def remove_dash(text):\n",
    "    text = re.sub(r'--', '', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def remove_3rdbreket(text):\n",
    "    text = text.replace(']', '').replace('[', '').replace(\"'\", \"\").replace('(', '').replace(')', '').replace('/', '')\n",
    "    return text\n",
    "\n",
    "#lemmatize\n",
    "from banglakit import lemmatizer as lem\n",
    "from banglakit.lemmatizer import BengaliLemmatizer\n",
    "lemmatizer = BengaliLemmatizer()\n",
    "\n",
    "def lemmatize_text(text): \n",
    "    lemmatized_text = []\n",
    "    for word in text.split():\n",
    "        lemmatized_text.append(lemmatizer.lemmatize(word, pos=lem.POS_PROPN))\n",
    "    return \" \".join(lemmatized_text)\n",
    "\n",
    "input_data = input_data.apply(lemmatize_text)\n",
    "input_data= input_data.apply(remove_prone)\n",
    "input_data = input_data.apply(remove_numbers)\n",
    "input_data = input_data.apply(remove_english_words)\n",
    "input_data = input_data.apply(remove_stopwords)\n",
    "input_data = input_data.apply(remove_perenthesis)\n",
    "input_data = input_data.apply(remove_dash)\n",
    "input_data = input_data.apply(remove_extra_spaces)\n",
    "input_data = input_data.apply(remove_3rdbreket)\n",
    "\n",
    "#input_data = input_data.apply(remove_symbols) unicode error here dont use it \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(input_data, targets, test_size=0.2, random_state=0)\n",
    "# validation set \n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "X_val = vectorizer.transform(X_val)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model slecetion with cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf = OneVsRestClassifier(LinearSVC(random_state=0))\n",
    "#make 10 fold cross validation \n",
    "display_scores(cross_val_score(clf, X_train, y_train, cv=10, scoring=\"accuracy\"))\n",
    "\n",
    "'''\n",
    "    Scores: [0.79620853 0.81042654 0.79810427 0.79336493 0.81119545 0.79791271\n",
    "    0.79886148 0.79316888 0.80929791 0.82827324]\n",
    "    Mean: 0.80368139428222\n",
    "    Standard deviation: 0.010481708200214835 \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svm classifier    \n",
    "clf = OneVsRestClassifier(svm.SVC(kernel='linear', C=5, gamma=1))\n",
    "#make 10 fold cross validation\n",
    "clf=display_scores(cross_val_score(clf, X_train, y_train, cv=10, scoring=\"accuracy\"))\n",
    "\n",
    "'''\n",
    "    Scores: [0.80473934 0.81516588 0.80379147 0.80663507 0.82637571 0.80929791\n",
    "    0.80550285 0.80265655 0.81499051 0.84345351]\n",
    "    Mean: 0.8132608793402699\n",
    "    Standard deviation: 0.012185016433768013\n",
    "    \n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dt classifier \n",
    "clf = OneVsRestClassifier(DecisionTreeClassifier(random_state=0))\n",
    "#10 fold cross validation\n",
    "clf=display_scores(cross_val_score(clf, X_train, y_train, cv=10, scoring=\"accuracy\"))\n",
    "#display_scores(cross_val_score(clf, X_train, y_train, cv=10, scoring=\"accuracy\"))\n",
    "'''\n",
    "    Scores: [0.83033175 0.81706161 0.82748815 0.8        0.82352941 0.83206831\n",
    "    0.80645161 0.80075901 0.80929791 0.84535104]\n",
    "    Mean: 0.8192338822090524\n",
    "    Standard deviation: 0.014264177653053867\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression classifier \n",
    "clf = OneVsRestClassifier(LogisticRegression(random_state=0))\n",
    "#make 10 fold cross validation\n",
    "display_scores(cross_val_score(clf, X_train, y_train, cv=10, scoring=\"accuracy\"))\n",
    "\n",
    "'''\n",
    "    Scores: [0.75165877 0.75924171 0.75734597 0.73080569 0.74383302 0.73529412\n",
    "    0.73339658 0.73529412 0.72106262 0.76375712]\n",
    "    Mean: 0.7431689703858917\n",
    "    Standard deviation: 0.01347878794175505\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#naive bayes classifier \n",
    "clf = OneVsRestClassifier(MultinomialNB())\n",
    "#10 fold cross validation\n",
    "display_scores(cross_val_score(clf, X_train, y_train, cv=10, scoring=\"accuracy\"))\n",
    "\n",
    "'''\n",
    "    Scores: [0.50521327 0.5478673  0.53175355 0.50047393 0.54079696 0.5370019\n",
    "    0.51612903 0.51328273 0.49240987 0.53605313]\n",
    "    Mean: 0.5220981681160463\n",
    "    Standard deviation: 0.018086532757600096\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#knn classifier \n",
    "clf = OneVsRestClassifier(KNeighborsClassifier(n_neighbors=3))\n",
    "display_scores(cross_val_score(clf, X_train, y_train, cv=10, scoring=\"accuracy\"))\n",
    "\n",
    "'''\n",
    "    Scores: [0.72890995 0.75165877 0.72511848 0.71279621 0.74762808 0.72296015\n",
    "    0.72390892 0.71157495 0.71157495 0.75142315]\n",
    "    Mean: 0.7287553621050928\n",
    "    Standard deviation: 0.01519843741387436\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradient boosting classifier \n",
    "clf = OneVsRestClassifier(GradientBoostingClassifier(random_state=0))\n",
    "display_scores(cross_val_score(clf, X_train, y_train, cv=10, scoring=\"accuracy\"))\n",
    "\n",
    "\n",
    "'''\n",
    "    Scores: [0.83696682 0.83127962 0.82559242 0.82369668 0.82827324 0.83965844\n",
    "    0.81024668 0.81119545 0.81688805 0.85009488]\n",
    "    Mean: 0.8273892281266579\n",
    "    Standard deviation: 0.01207050517222523\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make adaboost classifier \n",
    "clf = OneVsRestClassifier(AdaBoostClassifier(random_state=0))\n",
    "display_scores(cross_val_score(clf, X_train, y_train, cv=10, scoring=\"accuracy\"))\n",
    "'''\n",
    "    Scores: [0.80947867 0.7943128  0.78672986 0.77156398 0.80455408 0.79222011\n",
    "    0.79411765 0.78842505 0.79601518 0.80740038]\n",
    "    Mean: 0.7944817755874709\n",
    "    Standard deviation: 0.01059659213112092\n",
    "\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### summary \n",
    "\n",
    "##### Model evaluated \n",
    "Logistic Regression ,2. XGBoost , 3. SVM ,4. Naive Bayes ,5. KNN ,6. Decision Tree,7. AdaBoost ,8. Gradient Boosting ,9. Voting Classifier \n",
    "Model Evaluation base on Accuracy \n",
    "best performing model (accuracy >= 0.8)--> gradient boosting ,2. svm ,3. dt ,4. adaboost \n",
    " \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hyper parameter tuning \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# desion tree classifier parameters \n",
    "from sklearn.model_selection import GridSearchCV   \n",
    "clf = DecisionTreeClassifier(random_state=0) \n",
    "param_grid = [{ \n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'splitter': ['best', 'random'],\n",
    "    'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20],\n",
    "    \n",
    "}]\n",
    "#make grid search\n",
    "CV_clf = GridSearchCV(estimator=clf, param_grid=param_grid, cv= 10)\n",
    "CV_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#best parameters \n",
    "#print(CV_clf.best_params_) -->DecisionTreeClassifier(criterion='entropy', max_depth=20, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_clf_best = OneVsRestClassifier(DecisionTreeClassifier(criterion='entropy', max_depth=20, random_state=0))\n",
    "dt_clf_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(dt_clf_best, open('voting_clf.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make predictions\n",
    "y_pred = dt_clf_best.predict(X_test)\n",
    "y_pred = pd.DataFrame(y_pred, columns=targets.columns)\n",
    "y_pred.head()\n",
    "\n",
    "#save predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use default parameters, and train and test with small set of samples.\n",
    "svm_clf = OneVsRestClassifier(SVC())\n",
    "param_grid = {'estimator__C': [0.1, 1, 10, 100, 1000],  \n",
    "              'estimator__gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "              'estimator__kernel': ['rbf'],\n",
    "              'estimator__class_weight': ['balanced', None]}  \n",
    "\n",
    "\n",
    "\n",
    "#make grid search\n",
    "svm_clf_best = GridSearchCV(svm_clf, param_grid, cv=5, n_jobs=-1)\n",
    "svm_clf_best.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "'''\n",
    "{'estimator__C': 10, 'estimator__gamma': 1, 'estimator__kernel': 'rbf'}\n",
    "0.8566952151392379\n",
    "OneVsRestClassifier(estimator=SVC(C=10, gamma=1))\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train with best parameters \n",
    "svm_clf_best = OneVsRestClassifier(estimator=SVC(C=10, gamma=1))\n",
    "svm_clf_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(svm_clf_best, open('svm_clf.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV \n",
    "ada_clf = OneVsRestClassifier(AdaBoostClassifier(random_state=0))\n",
    "param_grid = [{'estimator__n_estimators': [50, 100, 200, 300 ],\n",
    "                'estimator__learning_rate': [0.1, 0.2, 0.3,],\n",
    "                'estimator__algorithm': ['SAMME', 'SAMME.R'],\n",
    "                'estimator__random_state': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "            }]\n",
    "\n",
    "#make grid search\n",
    "\n",
    "gs_clf = GridSearchCV(ada_clf, param_grid, cv=4, n_jobs=-1)\n",
    "gs_clf.fit(X_train, y_train)\n",
    "''' best parameters\n",
    "OneVsRestClassifier(estimator=AdaBoostClassifier(learning_rate=0.3,\n",
    "                                                 n_estimators=300,\n",
    "                                                 random_state=0))\n",
    "\n",
    "'''\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train with best parameters \n",
    "gs_clf = OneVsRestClassifier(AdaBoostClassifier(learning_rate=0.3,\n",
    "                                                 n_estimators=300,\n",
    "                                                 random_state=0))\n",
    "gs_clf.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(gs_clf, open('ada_clf.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make gradient boosting classifier with best parameters\n",
    "'''\n",
    "this model takes a long time to train, so tune it once with small set of parameters, and then never tune it again\n",
    "\n",
    "'''\n",
    "gb_clf = OneVsRestClassifier(GradientBoostingClassifier(random_state=0))\n",
    "param_grid = [{\n",
    "    'estimator__n_estimators': [300, 400, 500],\n",
    "    'estimator__max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "}]\n",
    "\n",
    "#make grid search\n",
    "gs_clf = GridSearchCV(gb_clf, param_grid, cv=5, n_jobs=-1)\n",
    "gs_clf.fit(X_train, y_train)\n",
    "\n",
    "#never tune it again \n",
    "#best parameters are {'estimator__max_depth': 10, 'estimator__min_samples_leaf': 1, 'estimator__min_samples_split': 2, 'estimator__n_estimators': 500}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train with best parameters \n",
    "gb_clf_best= OneVsRestClassifier(GradientBoostingClassifier(random_state=0, max_depth=10, n_estimators=500, min_samples_leaf=1, min_samples_split=2))\n",
    "gb_clf_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make voting classifier with best parameters \n",
    "from sklearn.ensemble import VotingClassifier\n",
    "voting_clf = OneVsRestClassifier(VotingClassifier( estimators=[('svm', svm_clf_best), ('dt', dt_clf_best), ('gb', gb_clf_best), ('ada', gs_clf)], voting='soft'))\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#make predictions on validation set \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "pickle.dump(voting_clf, open('voting_clf.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import voting_with_model \n",
    "\n",
    "print(y_pred)\n",
    "#make predictions on validation set\n",
    "y_pred = voting_with_model([svm_clf_best, dt_clf_best, gb_clf_best, gs_clf], X_val[455])\n",
    "# y_pred = pd.DataFrame(y_pred, columns=targets.columns)\n",
    "# y_pred.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4ef60fdc05b8c9d7c00029e41ed6e96799336c5489ef8cc1e2e0d70e844fa01c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
